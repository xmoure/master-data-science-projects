chisq_stats <- HWChisqStats(gendata_counts,pvalues = FALSE)
chisq_pval <- HWChisqStats(gendata_counts,pvalues = TRUE)
chisq_pval_sig <- sum(chisq_pval<0.05) # number of significant SNPs
chisq_pval_sig
expected_by_chance <- nrow(bim) * 0.05
chisq_stats <- HWChisqStats(gendata_counts,pvalues = FALSE)
chisq_pval <- HWChisqStats(gendata_counts,pvalues = TRUE)
chisq_pval_sig <- sum(chisq_pval<0.05) # number of significant SNPs
chisq_pval_sig
expected_by_chance <- nrow(bim) * 0.05
expected_by_chance
r2_gendata = c()
for(i in 2:p) { # generate all permutations
for(j in 1:(i-1)) {
a <- genotype(gendata[,i],sep="/")
b <- genotype(gendata[,j],sep="/")
r2_gendata <- c(r2_gendata, LD(a,b)$`R^2`)
}
}
r2_gendata = c()
for(i in 2:p) { # generate all permutations
for(j in 1:(i-1)) {
a <- genotype(FOXP2_data[,i],sep="/")
b <- genotype(FOXP2_data[,j],sep="/")
r2_gendata <- c(r2_gendata, LD(a,b)$`R^2`)
}
}
r2_gendata = c()
p <- ncol(FOXP2_data)
for(i in 2:p) { # generate all permutations
for(j in 1:(i-1)) {
a <- genotype(FOXP2_data[,i],sep="/")
b <- genotype(FOXP2_data[,j],sep="/")
r2_gendata <- c(r2_gendata, LD(a,b)$`R^2`)
}
}
plot(density(r2_gendata))
library(ggplot2)
# Assuming FOXP2_data is a dataframe where each column represents a SNP and each row represents an individual
# And assuming the SNPs are already coded numerically or as factors
# Calculate LD for all pairs of SNPs
num_SNPs <- ncol(FOXP2_data)
ld_matrix <- matrix(nrow = num_SNPs, ncol = num_SNPs)
for(i in 1:(num_SNPs-1)) {
for(j in (i+1):num_SNPs) {
# Assume the data is coded correctly for the LD function
ld_result <- LD(FOXP2_data[,i], FOXP2_data[,j])
ld_matrix[i,j] <- ld_result$r.squared  # Extract the R^2 statistic
ld_matrix[j,i] <- ld_matrix[i,j]  # The matrix is symmetric
}
}
knitr::opts_chunk$set(echo = TRUE)
APOE_data <- read.table("APOE/APOE.dat", header = TRUE)
APOE_data <- APOE_data[,2:ncol(APOE_data)]
n_individuals <- nrow(APOE_data)
n_SNPs <- ncol(APOE_data)
# Calculate the percentage of missing data
percent_missing <- sum(is.na(APOE_data)) / (n_individuals * n_SNPs) * 100
cat("\nNum individuals:",n_individuals, "\n")
cat("\nNum SNPs:",n_SNPs, "\n")
cat("\nPercentage missing:",percent_missing, "\n")
theoretical_haplotypes <- 2^n_SNPs
cat("\nTheoretically there can be :",theoretical_haplotypes,"haplotypes\n")
geno <- data.frame(row.names = row.names(APOE_data))
for(i in 1:ncol(APOE_data)){
geno <- cbind(geno,substr(APOE_data[,i],1,1),substr(APOE_data[,i],3,3))
}
geno_matrix <- as.matrix(geno)
snpts <- colnames(APOE_data)
haplo_em <- haplo.em(geno_matrix,locus.label = snpts)
library(genetics)
library(dplyr)
library(HardyWeinberg)
library(data.table)
library(psych)
install.packages("haplo.stats")
install.packages("haplo.stats")
library(haplo.stats)
knitr::opts_chunk$set(echo = TRUE)
APOE_data <- read.table("APOE/APOE.dat", header = TRUE)
APOE_data <- APOE_data[,2:ncol(APOE_data)]
n_individuals <- nrow(APOE_data)
n_SNPs <- ncol(APOE_data)
# Calculate the percentage of missing data
percent_missing <- sum(is.na(APOE_data)) / (n_individuals * n_SNPs) * 100
cat("\nNum individuals:",n_individuals, "\n")
cat("\nNum SNPs:",n_SNPs, "\n")
cat("\nPercentage missing:",percent_missing, "\n")
theoretical_haplotypes <- 2^n_SNPs
cat("\nTheoretically there can be :",theoretical_haplotypes,"haplotypes\n")
geno <- data.frame(row.names = row.names(APOE_data))
for(i in 1:ncol(APOE_data)){
geno <- cbind(geno,substr(APOE_data[,i],1,1),substr(APOE_data[,i],3,3))
}
geno_matrix <- as.matrix(geno)
snpts <- colnames(APOE_data)
haplo_em <- haplo.em(geno_matrix,locus.label = snpts)
haplotypes <- length(haplo_em$hap.prob)
cat("\nHaplotypes :",haplotypes,"\n")
probabilities <- sort(haplo_em$hap.prob,decreasing = T)
cat("\nProbabilities in decreasing order :",probabilities,"\n")
most_common <-  which.max(haplo_em$hap.prob)
cat("\nMost common :", most_common,"\n")
# most_common_haplotype <- haplo_em $haplotype[which(haplo_em $hap.prob == probabilities[1]),]
# mc_haplotype <- unlist(most_common_haplotype)
# cat("Most common haplotype:", mc_haplotype, "\n")
geno <- data.frame(row.names = row.names(APOE_data))
for(i in 1:ncol(APOE_data)){
geno <- cbind(geno,substr(APOE_data[,i],1,1),substr(APOE_data[,i],3,3))
}
geno_matrix <- as.matrix(geno)
snpts <- colnames(APOE_data)
haplo_em <- haplo.em(geno_matrix,locus.label = snpts)
haplotypes <- length(haplo_em$hap.prob)
cat("\nHaplotypes :",haplotypes,"\n")
probabilities <- sort(haplo_em$hap.prob,decreasing = T)
cat("\nProbabilities in decreasing order :",probabilities,"\n")
most_common <-  which.max(haplo_em$hap.prob)
cat("\nMost common :", most_common,"\n")
# most_common_haplotype <- haplo_em $haplotype[which(haplo_em $hap.prob == probabilities[1]),]
# mc_haplotype <- unlist(most_common_haplotype)
# cat("Most common haplotype:", mc_haplotype, "\n")
geno <- data.frame(row.names = row.names(APOE_data))
for(i in 1:ncol(APOE_data)){
geno <- cbind(geno,substr(APOE_data[,i],1,1),substr(APOE_data[,i],3,3))
}
geno_matrix <- as.matrix(geno)
snpts <- colnames(APOE_data)
haplo_em <- haplo.em(geno_matrix,locus.label = snpts)
haplotypes <- length(haplo_em$hap.prob)
cat("\nHaplotypes :",haplotypes,"\n")
probabilities <- sort(haplo_em$hap.prob,decreasing = T)
cat("\nProbabilities in decreasing order :",probabilities,"\n")
most_common <-  which.max(haplo_em$hap.prob)
cat("\nMost common :", most_common,"\n")
# most_common_haplotype <- haplo_em $haplotype[which(haplo_em $hap.prob == probabilities[1]),]
# mc_haplotype <- unlist(most_common_haplotype)
# cat("Most common haplotype:", mc_haplotype, "\n")
calculate_MAF <- function(geno_column) {
alleles <- unlist(strsplit(geno_column, split = "/", fixed = TRUE))
freqs <- table(alleles) / length(alleles)
maf <- min(freqs)
return(maf)
}
# Apply the function to each column/SNP
MAFs <- sapply(APOE_data, calculate_MAF)
filtered_data <- geno_data[, MAFs >= 0.10]
calculate_MAF <- function(geno_column) {
alleles <- unlist(strsplit(geno_column, split = "/", fixed = TRUE))
freqs <- table(alleles) / length(alleles)
maf <- min(freqs)
return(maf)
}
# Apply the function to each column/SNP
MAFs <- sapply(APOE_data, calculate_MAF)
filtered_data <- APOE_data[, MAFs >= 0.10]
haplo_result_filtered <- haplo.em(geno = filtered_data)
genotype_counts_matrix <- matrix(NA, nrow = length(df), ncol = 4, dimnames = list(colnames(df),c("AA", "AB", "BB", "NA")))
MAF_values <- numeric(ncol(APOE_data))
for (i in 1:nrow(bim_data)) {
a <- paste(bim_data[i,]$allele1, bim[i,]$allele2, sep="/")
g_counts <- MakeCounts(df[,i], alleles = a, sep="/")
genotype_counts_matrix[i, ] <- g_counts
genotype_counts <- genotype_counts_matrix[i,]
p_a <- (genotype_counts[1] + 0.5 * genotype_counts[2]) / sum(genotype_counts)
p_b <- (genotype_counts[3] + 0.5 * genotype_counts[2]) / sum(genotype_counts)
MAF <- min(p_a, p_b)
MAF_values[i] <- MAF
}
# Assuming 'geno_data' is a dataframe with your genotype data
# Each row represents an individual, and each column represents a SNP with genotypes as alleles (e.g., "A/A", "A/T", "T/T")
# Function to calculate MAF
calculate_MAF <- function(geno_column) {
# Split the genotypes into individual alleles and create a vector
alleles <- unlist(strsplit(geno_column, split = "/", fixed = TRUE))
# Calculate the frequency of each allele
freqs <- table(alleles) / (2 * length(geno_column))
# MAF is the minimum of the allele frequencies
maf <- min(freqs)
return(maf)
}
# Apply the MAF calculation function to each SNP column
MAFs <- sapply(APOE_data, calculate_MAF)
# Filter out SNPs with MAF below 0.10
geno_data_filtered <- APOE_data[, MAFs >= 0.10]
# Now you can rerun haplo.em on the filtered data
library(haplo.stats)
haplo_result_filtered <- haplo.em(geno = geno_data_filtered)
View(APOE_data)
# Assuming 'geno_data' is a dataframe with your genotype data
# Each row represents an individual, and each column represents a SNP with genotypes as alleles (e.g., "A/A", "A/T", "T/T")
# Function to calculate MAF
calculate_MAF <- function(snp_data) {
# Create a vector with all alleles, split by '/'
alleles <- unlist(strsplit(as.character(snp_data), split = "/", fixed = TRUE))
# Calculate frequencies of alleles
allele_freqs <- table(alleles) / (2 * length(snp_data))
# MAF is the frequency of the less common allele
maf <- min(allele_freqs)
return(maf)
}
# Apply the MAF calculation function to each SNP column
MAFs <- sapply(APOE_data, calculate_MAF)
# Filter out SNPs with MAF below 0.10
geno_data_filtered <- APOE_data[, MAFs >= 0.10]
geno_matrix_filtered <- as.matrix(geno_data_filtered)
haplo_result_filtered <- haplo.em(geno = geno_matrix_filtered)
# Assuming 'geno_data' is a dataframe with your genotype data
# Each row represents an individual, and each column represents a SNP with genotypes as alleles (e.g., "A/A", "A/T", "T/T")
# Function to calculate MAF
calculate_MAF <- function(snp_data) {
# Create a vector with all alleles, split by '/'
alleles <- unlist(strsplit(as.character(snp_data), split = "/", fixed = TRUE))
# Calculate frequencies of alleles
allele_freqs <- table(alleles) / (2 * length(snp_data))
# MAF is the frequency of the less common allele
maf <- min(allele_freqs)
return(maf)
}
# Apply the MAF calculation function to each SNP column
MAFs <- sapply(APOE_data, calculate_MAF)
# Filter out SNPs with MAF below 0.10
geno_data_filtered <- APOE_data[, MAFs >= 0.10]
geno_matrix_filtered <- as.matrix(geno_data_filtered)
colnames(geno_matrix_filtered) <- snp_names_filtered
# Assuming 'geno_data' is a dataframe with your genotype data
# Each row represents an individual, and each column represents a SNP with genotypes as alleles (e.g., "A/A", "A/T", "T/T")
# Function to calculate MAF
calculate_MAF <- function(snp_data) {
# Create a vector with all alleles, split by '/'
alleles <- unlist(strsplit(as.character(snp_data), split = "/", fixed = TRUE))
# Calculate frequencies of alleles
allele_freqs <- table(alleles) / (2 * length(snp_data))
# MAF is the frequency of the less common allele
maf <- min(allele_freqs)
return(maf)
}
# Apply the MAF calculation function to each SNP column
MAFs <- sapply(APOE_data, calculate_MAF)
# Filter out SNPs with MAF below 0.10
geno_data_filtered <- APOE_data[, MAFs >= 0.10]
geno_matrix_filtered <- as.matrix(geno_data_filtered)
snp_names_filtered <- colnames(geno_data_filtered)
haplo_result_filtered <- haplo.em(geno = geno_matrix_filtered, locus.label = snp_names_filtered)
# Assuming 'geno_data' is a dataframe with your genotype data
# Each row represents an individual, and each column represents a SNP with genotypes as alleles (e.g., "A/A", "A/T", "T/T")
# Function to calculate MAF
calculate_MAF <- function(snp_data) {
# Create a vector with all alleles, split by '/'
alleles <- unlist(strsplit(as.character(snp_data), split = "/", fixed = TRUE))
# Calculate frequencies of alleles
allele_freqs <- table(alleles) / (2 * length(snp_data))
# MAF is the frequency of the less common allele
maf <- min(allele_freqs)
return(maf)
}
# Apply the MAF calculation function to each SNP column
MAFs <- sapply(APOE_data, calculate_MAF)
# Filter out SNPs with MAF below 0.10
geno_data_filtered <- APOE_data[, MAFs >= 0.10]
geno_matrix_filtered <- as.matrix(geno_data_filtered)
library(haplo.stats)
# Function to convert genotype data to numeric encoding
convert_genotypes <- function(snp_data) {
# Split the genotypes into individual alleles and create a vector
alleles <- unlist(strsplit(as.character(snp_data), split = "/", fixed = TRUE))
# Convert alleles to numeric factor codes
allele_codes <- as.numeric(factor(alleles))
# Create a matrix with a column for each allele
matrix(allele_codes, ncol = 2, byrow = TRUE)
}
# Apply the conversion to each SNP in the filtered dataset
numeric_genotypes_list <- lapply(geno_data_filtered, convert_genotypes)
# Combine the numeric genotype data for all SNPs
numeric_genotypes <- do.call(cbind, numeric_genotypes_list)
# Now we have a properly formatted numeric matrix for haplo.em
geno_matrix_filtered <- as.matrix(numeric_genotypes)
# Estimate haplotype frequencies using haplo.em
haplo_result_filtered <- haplo.em(geno = geno_matrix_filtered, locus.label = snp_names_filtered)
# Output the number of haplotypes
num_haplotypes_filtered <- length(haplo_result_filtered$haplo.freq)
print(num_haplotypes_filtered)
# Assuming you have the original number of haplotypes from before filtering
num_haplotypes_original <- length(haplo_result$haplo.freq)  # Replace with actual count
View(APOE_data)
bim_data <- read.table("APOE/APOE.bim", header=FALSE)
genotype_counts_matrix <- matrix(NA, nrow = length(APOE_data), ncol = 4, dimnames = list(colnames(df),c("AA", "AB", "BB", "NA")))
MAF_values <- numeric(ncol(df))
bim_data <- read.table("APOE/APOE.bim", header=FALSE)
genotype_counts_matrix <- matrix(NA, nrow = length(APOE_data), ncol = 4, dimnames = list(colnames(df),c("AA", "AB", "BB", "NA")))
MAF_values <- numeric(ncol(APOE_data))
for (i in 1:nrow(bim_data)) {
a <- paste(bim_data[i,]$allele1, bim_data[i,]$allele2, sep="/")
g_counts <- MakeCounts(APOE_data[,i], alleles = a, sep="/")
genotype_counts_matrix[i, ] <- g_counts
genotype_counts <- genotype_counts_matrix[i,]
p_a <- (genotype_counts[1] + 0.5 * genotype_counts[2]) / sum(genotype_counts)
p_b <- (genotype_counts[3] + 0.5 * genotype_counts[2]) / sum(genotype_counts)
MAF <- min(p_a, p_b)
MAF_values[i] <- MAF
}
library(genetics)
library(dplyr)
library(HardyWeinberg)
library(data.table)
library(psych)
install.packages("haplo.stats")
library(genetics)
library(dplyr)
library(HardyWeinberg)
library(data.table)
library(psych)
install.packages("haplo.stats")
install.packages("haplo.stats")
library(haplo.stats)
knitr::opts_chunk$set(echo = TRUE)
FOXP2_data <- read.table("FOXP2/FOXP2.dat", header = TRUE)
FOXP2_data <- FOXP2_data[,2:ncol(FOXP2_data)]
n_individuals <- nrow(FOXP2_data)
n_SNPs <- ncol(FOXP2_data)
percent_missing <- sum(is.na(FOXP2_data)) / (n_individuals * n_SNPs) * 100
cat("\nNum individuals:",n_individuals, "\n")
cat("\nNum SNPs:",n_SNPs, "\n")
cat("\nPercentage missing:",percent_missing, "\n")
rs34684677 <- FOXP2_data[,c("rs34684677")]
rs2894715 <- FOXP2_data[,c("rs2894715")]
rs34684677.gen <- genotype(rs34684677,sep="/")
APOE_data <- read.table("APOE/APOE.dat", header = TRUE)
APOE_data <- APOE_data[,2:ncol(APOE_data)]
n_individuals <- nrow(APOE_data)
n_SNPs <- ncol(APOE_data)
# Calculate the percentage of missing data
percent_missing <- sum(is.na(APOE_data)) / (n_individuals * n_SNPs) * 100
cat("\nNum individuals:",n_individuals, "\n")
cat("\nNum SNPs:",n_SNPs, "\n")
cat("\nPercentage missing:",percent_missing, "\n")
theoretical_haplotypes <- 2^n_SNPs
cat("\nTheoretically there can be :",theoretical_haplotypes,"haplotypes\n")
geno <- data.frame(row.names = row.names(APOE_data))
for(i in 1:ncol(APOE_data)){
geno <- cbind(geno,substr(APOE_data[,i],1,1),substr(APOE_data[,i],3,3))
}
geno_matrix <- as.matrix(geno)
snpts <- colnames(APOE_data)
haplo_em <- haplo.em(geno_matrix,locus.label = snpts)
haplotypes <- length(haplo_em$hap.prob)
cat("\nHaplotypes :",haplotypes,"\n")
probabilities <- sort(haplo_em$hap.prob,decreasing = T)
cat("\nProbabilities in decreasing order :",probabilities,"\n")
most_common <-  which.max(haplo_em$hap.prob)
cat("\nMost common :", most_common,"\n")
# most_common_haplotype <- haplo_em $haplotype[which(haplo_em $hap.prob == probabilities[1]),]
# mc_haplotype <- unlist(most_common_haplotype)
# cat("Most common haplotype:", mc_haplotype, "\n")
bim_data <- read.table("APOE/APOE.bim", header=FALSE)
genotype_counts_matrix <- matrix(NA, nrow = length(APOE_data), ncol = 4, dimnames = list(colnames(df),c("AA", "AB", "BB", "NA")))
MAF_values <- numeric(ncol(APOE_data))
for (i in 1:nrow(bim_data)) {
a <- paste(bim_data[i,]$allele1, bim_data[i,]$allele2, sep="/")
g_counts <- MakeCounts(APOE_data[,i], alleles = a, sep="/")
genotype_counts_matrix[i, ] <- g_counts
genotype_counts <- genotype_counts_matrix[i,]
p_a <- (genotype_counts[1] + 0.5 * genotype_counts[2]) / sum(genotype_counts)
p_b <- (genotype_counts[3] + 0.5 * genotype_counts[2]) / sum(genotype_counts)
MAF <- min(p_a, p_b)
MAF_values[i] <- MAF
}
library(genetics)
library(dplyr)
library(HardyWeinberg)
library(data.table)
library(psych)
install.packages("haplo.stats")
install.packages("haplo.stats")
knitr::opts_chunk$set(echo = TRUE)
library(haplo.stats)
FOXP2_data <- read.table("FOXP2/FOXP2.dat", header = TRUE)
FOXP2_data <- FOXP2_data[,2:ncol(FOXP2_data)]
n_individuals <- nrow(FOXP2_data)
n_SNPs <- ncol(FOXP2_data)
percent_missing <- sum(is.na(FOXP2_data)) / (n_individuals * n_SNPs) * 100
cat("\nNum individuals:",n_individuals, "\n")
cat("\nNum SNPs:",n_SNPs, "\n")
cat("\nPercentage missing:",percent_missing, "\n")
rs34684677 <- FOXP2_data[,c("rs34684677")]
rs2894715 <- FOXP2_data[,c("rs2894715")]
rs34684677.gen <- genotype(rs34684677,sep="/")
setwd("~/Desktop/StatisticsLab4")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(genetics)
library(MASS)
library(data.table)
library(ggplot2)
data <- fread("Chr21.dat")
genetic_data <- data[, -c(1:6), with=FALSE]
View(genetic_data)
mds <- cmdscale(manhattan_distances, k = 2, eig = T)
manhattan_distances <- as.matrix(dist(genetic_data, method = "manhattan"))
submatrix_5x5 <- manhattan_distances[1:5, 1:5]
submatrix_5x5
mds <- cmdscale(manhattan_distances, k = 2, eig = T)
mds_scaled <- as.data.frame(mds$points)
# Plot the map
plot(mds_scaled$V1,mds_scaled$V2, main = "MDS Plot",
xlab = "Dimension 1", ylab = "Dimension 2")
threshold <- 0
num_subpop1 <- sum(mds$points[,1] < threshold)
num_subpop2 <- sum(mds$points[,1] >= threshold)
num_subpop1
num_subpop2
set.seed(42)
kmeans_result <- kmeans(mds$points, centers = 2)
# Count the number of individuals in each cluster
table(kmeans_result$cluster)
plot(mds$points[, 1], mds$points[, 2], col = kmeans_result$cluster,
xlab = "Dimension 1", ylab = "Dimension 2",
main = "MDS Plot with K-Means Clustering")
legend("topright", legend = c("Subpopulation 1", "Subpopulation 2"),
col = 1:2, pch = 1)
gof <-mds$GOF
cat("\nGOF:",gof, "\n")
mds_distances <- as.matrix(dist(mds$points))
obs_dist <- as.vector(manhattan_distances)
est_dist <- as.vector(mds_distances)
plot(obs_dist, est_dist, xlab = "Observed Distances",
ylab = "Estimated Distances",
main = "Observed vs Estimated Distances")
abline(0, 1, col = "blue", lty = 1)
reg <- lm(est_dist ~ obs_dist)
abline(reg, col = "red")
summary(reg)
r_squared <- summary(reg)$r.squared
print(paste("Coefficient of Determination (R-squared):", r_squared))
set.seed(12345)
n <- nrow(genetic_data)
m <- 2
init <- scale(matrix(runif(m * n), ncol = m), scale = FALSE)
nonmetric_mds <- isoMDS(manhattan_distances, k = 2, y = init)
# Plot the non-metric MDS map
plot(nonmetric_mds$points, main = "Non-Metric MDS Plot", xlab = "Dimension 1",
ylab = "Dimension 2")
times <- 8
par(mfrow = c(2, 3))
stress_vals <- numeric(times) # To store stress values
mds_run_results <- list() # To store MDS results for each run
set.seed(123)
for (i in 1:times) {
# Random initial configuration
init <- scale(matrix(runif(2 * nrow(manhattan_distances)), ncol = 2),
scale = FALSE)
mds_run_results[[i]] <- isoMDS(manhattan_distances, k = 2, y = init)$points
plot(mds_run_results[[i]], main = paste("Run", i), xlab = "D1", ylab = "D2",
pch = 19, col = "red")
stress_vals[i] <- isoMDS(manhattan_distances, k = 2, y = init)$stress
}
par(mfrow = c(1, 1))
cat("Stress values: ", stress_vals, "\n")
stress_values <- numeric(50)  # to store stress values for each dimension
dimensions <- 1:50
cmdscale_result <- cmdscale(manhattan_distances, eig = TRUE,
k = max(dimensions))
for (k in dimensions) {
init <- cmdscale_result$points[, 1:k, drop = FALSE]
# Run non-metric MDS with varying dimensions
mds_result <- isoMDS(manhattan_distances, k = k, y=init)
# Store the stress value
stress_values[k] <- mds_result$stress
}
# Find the number of dimensions needed for stress below 10
good_dims <- which(stress_values < 10)
# Plot stress values against number of dimensions
plot(dimensions, stress_values, type = "b", xlab = "Number of Dimensions",
ylab = "Stress Value", main = "Stress vs. Number of Dimensions")
if (length(good_dims) > 0) {
cat("Minimum dimensions needed for stress below 10:", min(good_dims), "\n")
} else {
cat("No solution with stress below 10 found up to 50 dimensions.\n")
}
n_runs <- 100
n <- nrow(manhattan_distances)
stress_values <- numeric(n_runs)
mds_configs <- list()
for (i in 1:n_runs) {
set.seed(i)
init <- scale(matrix(runif(2 * n), ncol = 2), scale = FALSE)
mds_run <- isoMDS(manhattan_distances, k = 2, y = init)
stress_values[i] <- mds_run$stress
mds_configs[[i]] <- mds_run$points
}
# best and worst runs
best_run <- which.min(stress_values)
worst_run <- which.max(stress_values)
cat("Best run stress:", stress_values[best_run], "\n")
cat("Worst run stress:", stress_values[worst_run], "\n")
# Plot the best and worst MDS configurations
par(mfrow=c(1, 2))
plot(mds_configs[[best_run]][,1], mds_configs[[best_run]][,2],
main = paste("Best Run (Stress:", round(stress_values[best_run], 4), ")"),
xlab = "Dimension 1", ylab = "Dimension 2", pch = 19)
plot(mds_configs[[worst_run]][,1], mds_configs[[worst_run]][,2],
main = paste("Worst Run (Stress:",
round(stress_values[worst_run], 4), ")"),
xlab = "Dimension 1", ylab = "Dimension 2", pch = 19)
par(mfrow=c(1, 1))
# best non-metric MDS run
best_nonmetric_mds_points <- mds_configs[[best_run]]
cor_matrix <- cor(mds_scaled, best_nonmetric_mds_points)
print(cor_matrix)
image(1:2, 1:2, as.matrix(cor_matrix), main="Correlation Matrix", xlab="Metric MDS Dimensions", ylab="Non-metric MDS Dimensions", xaxt='n', yaxt='n')
axis(1, at=1:2, labels=c("Dimension 1", "Dimension 2"))
axis(2, at=1:2, labels=c("Dimension 1", "Dimension 2"), las=2)  # 'las=2' makes the y-axis labels perpendicular to the axis
