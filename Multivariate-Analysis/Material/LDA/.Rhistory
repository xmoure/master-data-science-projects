cat.sort <- function(x){reorder(x,x,function(y){-length(y)})}
cat.var <- which(sapply(dd, is.factor))
for (i in cat.var){
dd[,i] <- cat.sort(dd[,i])
}
c1 <- ggplot(dd, aes(x=Category)) + ggtitle("Category") + xlab("Categories") +
geom_bar(aes(y = 100*(..count..)/sum(..count..))) + ylab("Percentage") + coord_flip() +
scale_x_discrete(limits = rev(levels(dd$Category)))
c2 <- ggplot(dd, aes(x=Content.Rating)) + ggtitle("Content rating") + xlab("Content rating") +
geom_bar(aes(y = 100*(..count..)/sum(..count..))) + ylab("Percentage") + coord_flip() +
scale_x_discrete(limits = rev(levels(dd$Content.Rating)))
ggplot(original_table, aes(x=Category)) + ggtitle("Category original") + xlab("Category") +
geom_bar(aes(y = 100*(..count..)/sum(..count..))) + ylab("Percentage") + coord_flip() +
scale_x_discrete(limits = rev(levels(dd$Content.Rating)))
#Pie charts of categorical variables
pie_chart1 <- ggplot(dd, aes(x=factor(1), fill=Category)) +
geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 1) + coord_polar(theta="y") +
theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), legend.title=element_blank()) +
xlab("") + ylab("") + ggtitle("Categories")
plot(pie_chart1)
pie_chart2 <- ggplot(dd, aes(x=factor(1), fill=Content.Rating)) +
geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 1) + coord_polar(theta="y") +
theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), legend.title=element_blank()) +
xlab("") + ylab("") + ggtitle("Content Rating")
plot(pie_chart2)
CAT = function(xfeature, yfeature, xlabel, ylabel) {
ggplot(dd, aes(x = xfeature, y = yfeature, fill = xfeature)) +
geom_boxplot(outlier.colour = "red", outlier.shape = 1, show.legend = F) +
stat_boxplot(geom = "errorbar", width = 0.5) +
labs(x = xlabel, y = ylabel, title = paste(ylabel, "vs", xlabel)) +
plot_theme
}
x1 = CAT(dd$Category, dd$Rating,
"Category", "Rating")
x2 = CAT(dd$Content.Rating, dd$Rating,
"Content rating",  "Rating")
x3 = CAT(dd$In.App.Purchases, dd$Rating, "In app purchases", "Rating")
x4 = CAT(dd$Ad.Supported, dd$Rating, "Add supported", "Rating")
grid.arrange(c1, pie_chart1)
grid.arrange(c2, pie_chart2)
plot(x1)
plot(x2)
plot(x3)
plot(x4)
#Univariate and Multivariate Analysis (Categorical Variables)
#Sort categorical variables in descending order
cat.sort <- function(x){reorder(x,x,function(y){-length(y)})}
cat.var <- which(sapply(dd, is.factor))
for (i in cat.var){
dd[,i] <- cat.sort(dd[,i])
}
c1 <- ggplot(dd, aes(x=Category)) + ggtitle("Category") + xlab("Categories") +
geom_bar(aes(y = 100*(..count..)/sum(..count..))) + ylab("Percentage") + coord_flip() +
scale_x_discrete(limits = rev(levels(dd$Category)))
c2 <- ggplot(dd, aes(x=Content.Rating)) + ggtitle("Content rating") + xlab("Content rating") +
geom_bar(aes(y = 100*(..count..)/sum(..count..))) + ylab("Percentage") + coord_flip() +
scale_x_discrete(limits = rev(levels(dd$Content.Rating)))
ggplot(original_table, aes(x=Category)) + ggtitle("Category original") + xlab("Category") +
geom_bar(aes(y = 100*(..count..)/sum(..count..))) + ylab("Percentage") + coord_flip() +
scale_x_discrete(limits = rev(levels(dd$Content.Rating)))
#Pie charts of categorical variables
pie_chart1 <- ggplot(dd, aes(x=factor(1), fill=Category)) +
geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 1) + coord_polar(theta="y") +
theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), legend.title=element_blank()) +
xlab("") + ylab("") + ggtitle("Categories")
plot(pie_chart1)
pie_chart2 <- ggplot(dd, aes(x=factor(1), fill=Content.Rating)) +
geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 1) + coord_polar(theta="y") +
theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), legend.title=element_blank()) +
xlab("") + ylab("") + ggtitle("Content Rating")
plot(pie_chart2)
CAT = function(xfeature, yfeature, xlabel, ylabel) {
ggplot(dd, aes(x = xfeature, y = yfeature, fill = xfeature)) +
geom_boxplot(outlier.colour = "red", outlier.shape = 1, show.legend = F) +
stat_boxplot(geom = "errorbar", width = 0.5) +
labs(x = xlabel, y = ylabel, title = paste(ylabel, "vs", xlabel)) +
plot_theme
}
x1 = CAT(dd$Category, dd$Rating,
"Category", "Rating")
x2 = CAT(dd$Content.Rating, dd$Rating,
"Content rating",  "Rating")
x3 = CAT(dd$In.App.Purchases, dd$Rating, "In app purchases", "Rating")
x4 = CAT(dd$Ad.Supported, dd$Rating, "Add supported", "Rating")
x5 = CAT(dd$Category, dd$Size, "Category", "Size")
grid.arrange(c1, pie_chart1)
grid.arrange(c2, pie_chart2)
plot(x1)
plot(x2)
plot(x3)
plot(x4)
plot(x5)
setwd("~/Downloads")
# Load Required Packages: to be increased over the course
options(contrasts=c("contr.treatment","contr.treatment"))
requiredPackages <- c("missMDA","effects","FactoMineR","car","factoextra","RColorBrewer","ggplot2","dplyr","ggmap","ggthemes","knitr","chemometrics","rpart","ROCR","corrr","readxl","RColorBrewer","ggplot2","corrplot","plotly","xlsx","reshape2","scales","stargazer","kableExtra")
package.check <- lapply(requiredPackages, FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}
})
#verify they are loaded
search()
setwd("~/Downloads")
# Clear plots
if(!is.null(dev.list())) dev.off()
# Clean workspace
rm(list=ls())
setwd("~/Downloads")
pathfile<-"~/Downloads/Pizza.RData"
# pizza <- read.table("Pizza.csv", header=T, dec=".", sep=",",stringsAsFactors =T)
# df <- pizza
# row.names(pizza) <- paste0(pizza$brand,".",pizza$id)
# save(list=c("pizza","df"),file="Pizza.RData")
load(paste0(pathfile,"Pizza.RData"))
# Clear plots
if(!is.null(dev.list())) dev.off()
# Clean workspace
rm(list=ls())
setwd("~/Downloads")
pathfile<-"~/Downloads/"
# pizza <- read.table("Pizza.csv", header=T, dec=".", sep=",",stringsAsFactors =T)
# df <- pizza
# row.names(pizza) <- paste0(pizza$brand,".",pizza$id)
# save(list=c("pizza","df"),file="Pizza.RData")
load(paste0(pathfile,"Pizza.RData"))
summary(df)
names(df)
vars_res <- names(df)[c(9)]
vars_con <- names(df)[c(3:8)]
vars_dis <- names(df)[c(10:11)]
acf(df$cal)
library(lmtest)
dwtest(df$cal~1)
names(df)
df$ingredients <- rowSums(df[,c(3:6,8)])
summary( df$ingredients )
table( df$ingredients )
Boxplot( df[,c(3:9)])
unidesfat <- summary( df$fat ); unidesfat
thrusout <- unidesfat[5]+3*( unidesfat[5]-unidesfat[2]);thrusout
llusout <- which( df$fat > thrusout ); llusout
df$sevout <- 0
df$sevout[ llusout ] <- 1
boxplot( df$fat, range=3)$out
Boxplot( df$fat, range=3, id=list(n=Inf,labels=rownames(df)))
unidesash <- summary( df$ash ); unidesash
thrusout <- unidesash[5]+3*( unidesash[5]-unidesash[2]);thrusout
llusout <- which( df$ash > thrusout ); llusout
if (length(llusout) > 0 ) df$sevout[ llusout ] <- df$sevout[ llusout ] + 1
unidessod <- summary( df$sodium ); unidessod
thrusout <- unidessod[5]+3*( unidessod[5]-unidessod[2]);thrusout
llusout <- which( df$sodium > thrusout ); llusout
if (length(llusout) > 0 ) df$sevout[ llusout ] <- df$sevout[ llusout ] + 1
unidescal <- summary( df$cal ); unidescal
thrusout <- unidescal[5]+3*( unidescal[5]-unidescal[2]);thrusout
llusout <- which( df$cal > thrusout ); llusout
if (length(llusout) > 0 ) df$sevout[ llusout ] <- df$sevout[ llusout ] + 1
summary( df$sevout )
table( df$sevout )
library(chemometrics)
lapply(df[ ,3:9],table)
res.mout <- Moutlier( df[ , c(4:9)], quantile = 0.999 )
par(mfrow=c(1,1))
plot( res.mout$md, res.mout$rd )
abline( h=res.mout$cutoff, lwd=2, col="red")
abline( v=res.mout$cutoff, lwd=2, col="red")
llmout <- which( ( res.mout$md > res.mout$cutoff ) & (res.mout$rd > res.mout$cutoff) );llmout
df[llmout,]
res.mout$md[llmout]
df$mout <- 0
df$mout[ llmout ] <- 1
df$mout <- factor( df$mout, labels = c("MvOut.No","MvOut.Yes"))
res.con <- condes( df[,c(1,3:9)], num.var=8, proba = 0.01 )
res.con$quanti
res.con$quali
res.con$category
plot(df[,c(9,3:8)])
cor(df[,c(9,3:8)], method="spearman")
corrplot(cor(df[,c(9,3:8)], method="spearman"), is.corr=T)
acf(df$cal)
library(lmtest)
dwtest(df$cal~1)
res.con <- condes( df[,c(1,3:9)], num.var=8, proba = 0.01 )
res.con$quanti
res.con$quali
res.con$category
plot(df[,c(9,3:8)])
cor(df[,c(9,3:8)], method="spearman")
corrplot(cor(df[,c(9,3:8)], method="spearman"), is.corr=T)
res.con <- condes( df[,c(1,3:9)], num.var=8, proba = 0.01 )
res.con$quanti
res.con$quali
res.con$category
res.cat <- catdes( df[,c(1,3:9)], num.var=1, proba = 0.01 )
res.cat$quanti.var
res.cat$quanti
res.cat <- catdes( df[,c(1,3:9)], num.var=1, proba = 0.01 )
res.cat$quanti.var
res.cat$quanti
res.cat <- catdes( df[,c(1,3:9)], num.var=1, proba = 0.01 )
res.cat$quanti.var
res.cat <- catdes( df[,c(1,3:9)], num.var=1, proba = 0.01 )
res.cat$quanti.var
res.cat$quanti
hist(df$cal,30)
hist(log(df$cal),30)
shapiro.test( log(df$cal) )
library(fitdistrplus)
descdist( df$cal )
library(FactoMineR)
data(tea)
res.mca = MCA(tea, ncp=20, quanti.sup=19, quali.sup=c(20:36), graph=FALSE)
res.hcpc = HCPC(res.mca)
View(tea)
View(tea)
res.mca = MCA(tea, ncp=20, quanti.sup=19, quali.sup=c(20:36), graph=FALSE)
res.hcpc = HCPC(res.mca)
###Also install RTools in your computer if library(RWeka) will be used
library(DAAG)
library(party)
library(rpart)
library(rpart.plot)
library(mlbench)
library(caret)
library(pROC)
library(tree)
library(C50)
library(printr)
library(randomForest)
#############Classification Tree##############
dd <- read.table("Playstore-preprocessed.csv",header=T, sep=",", dec='.',stringsAsFactors=TRUE)
head(dd)
mydata<-dd
dd$f.rating<-""
l <- which(dd$Rating >= 1 & dd$Rating<3)
dd$f.rating[l] <- "1-3"
l <- which(dd$Rating >= 3)
dd$f.rating[l] <- "3-4"
l <- which(dd$Rating >= 4)
dd$f.rating[l] <- "4-5"
# l <- which(dd$Rating >= 1 & dd$Rating<3.5)
# dd$f.rating[l] <- "1-3.5"
# l <- which(dd$Rating >= 3.5 & dd$Rating <4.5)
# dd$f.rating[l] <- "3.5-4.5"
# l <- which(dd$Rating >= 4.5)
# dd$f.rating[l] <- "4.5-5"
dd$f.rating <- as.factor(dd$f.rating)
levels(dd$f.rating)
table(dd$f.rating)
original_dd<-dd
l <- which(dd$Rating >= 1 & dd$Rating<3)
new <- rbind(dd,dd[l,])
dd <- rbind(dd[l,],new)
l <- which(dd$Rating >= 4)
copy<-dd[sample(l,3500),]
dd<-dd[-l,]
dd <- rbind(dd,copy)
table(dd$f.rating)
# dd$Rating<-NULL
dd$f.rating<-NULL
# l <- which(dd$Rating >= 3.5 & dd$Rating <4.5)
# copy<-dd[sample(l,3500),]
# dd<-dd[-l,]
# dd <- rbind(dd,copy)
table(dd$f.rating)
#dd$Rating<-NULL
dd<- dd[sample(1:nrow(dd)), ]
View(dd)
###### Modelling rpart
### Train & Test Partions
set.seed(1234)
ind <- sample(2, nrow(dd), replace = T, prob = c(0.7, 0.3))
train <- dd[ind == 1,]
test <- dd[ind == 2,]
#Tree Classification
tree <- rpart(f.rating ~., data = train)
View(dd)
original_dd<-dd
l <- which(dd$Rating >= 1 & dd$Rating<3)
new <- rbind(dd,dd[l,])
dd <- rbind(dd[l,],new)
l <- which(dd$Rating >= 4)
copy<-dd[sample(l,3500),]
dd<-dd[-l,]
dd <- rbind(dd,copy)
table(dd$f.rating)
# dd$Rating<-NULL
dd$f.rating<-NULL
# l <- which(dd$Rating >= 3.5 & dd$Rating <4.5)
# copy<-dd[sample(l,3500),]
# dd<-dd[-l,]
# dd <- rbind(dd,copy)
table(dd$f.rating)
#dd$Rating<-NULL
dd<- dd[sample(1:nrow(dd)), ]
View(dd)
setwd("~/Desktop/Session12-12")
load("WomenIf.RData")
load("Womenlf.RData")
summary(womenlf)
str(womenlf)
df <- womenlf
womenlf$bwork<-ifelse(womenlf$work=="not_work",0,1)
womenlf$bwork<-factor(womenlf$bwork,labels=c("not_work","work"))
hm1m0 <- glm( bwork ~ 1, family="binomial",data=womenlf)
#Too big model
hm1m9 <- glm( bwork ~ sons*income + sons *region, family="binomial",data=womenlf)
step(hm1m9)
hm1m3 <- glm( bwork ~ sons + income, family="binomial",data=womenlf)
summary(hm1m3)
coef(hm1m3)
exp(coef(hm1m3))
View(df)
View(womenlf)
100*(1-exp(-1.57564843))
#Interpretation in he probability scale
propsample <- prop.table(table(womenlf$bwork)); propsample
0.5893536 * 0.4106464 * coef(hm1m3)[2]
#income
# odds scale interpretation?
coef(hm1m3)[3]
exp(coef(hm1m3)[3])
100*(1-exp(coef(hm1m3)[3]))
# for each additional unit in income odds decrease by 4%
0.5893536 * 0.4106464 * coef(hm1m3)[3]
library(nnet)
mm0 <-multinom(  work~sons+income, data=womenlf,weight=ones )
summary(mm0)
library(nnet)
mm3 <-multinom(  work~sons+income, data=womenlf,weight=ones )
summary(mm3)
library(nnet)
mm0 <-multinom(  work~1, data=womenlf,weight=ones ) # null model
mm3 <-multinom(  work~sons+income, data=womenlf,weight=ones )
summary(mm3)
library(nnet)
mm0 <-multinom(  work~1, data=womenlf,weight=ones ) # null model
summary(mm0)
mm3 <-multinom(  work~sons+income, data=womenlf,weight=ones )
summary(mm3)
coef(mm3)
exp(coef(mm3))
100*(exp(coef(mm3)[1,2:3])-1)
#odds scale FT (full time)  vs NW
exp(coef(mm3)[2,2:3])
100*(1- exp(coef(mm3)[1,2:3]))
mean(womenlf$income)
# Interpret sons absent and income on the mean
mean(womenlf$income)
mm3c <-multinom( work~ sons+I(income - mean(womenlf$income)), data=womenlf,weight=ones )
summary(mm3c)
lopPT <- coef(mm3c)[1,1];lopPT
lopFT <- coef(mm3c)[2,1];lopFT
opPT <- exp(lopPT);opPT
opFT <- exp(lopFT);opFT
pNW <- (1/(1+opPT+opFT));pNW
predict(mm3c, newdata=data.frame(sons="absent",income=14.76),type="probs")
predict(mm3c, newdata=data.frame(sons="absent",income=14.76),type="class")
tt<-table(predict(mm3),womenlf$work);tt
100*sum(diag(tt))/sum(tt)
library(MASS)
om0 <-polr( work~1, data=womenlf,weight=ones )
library(MASS)
om0 <-polr( work~1, data=womenlf,weight=ones )
om9 <-polr( work~sons*income + region, data=womenlf,weight=ones )
step(om9)
library(MASS)
om0 <-polr( work~1, data=womenlf,weight=ones )
om9 <-polr( work~sons*income + region, data=womenlf,weight=ones )
om3 <-step(om9)
summary(om3)
summary(om0)
summary(om3)
#predict probabilities sons absent and income on the mean. Use the trick om3c
om3c <-polr( work~ sons+I(income - mean(womenlf$income)), data=womenlf,weight=ones )
summary(om3c)
om3c$zeta
clogogg1 <- om3c$zeta[1]; clogogg1 #linea predictors!
clogogg2 <- om3c$zeta[2]; clogogg2
gam1 <- exp(clogogg1)/ (1-exp(clogogg1)); gam1
gam2 <- exp(clogogg2)/ (1-exp(clogogg2)); gam2
pNW <- gam1; pNW
pPT <- gam2 - gam1; pPT
pFT <- 1-gam2; pFT
setwd("~/Desktop/LDA")
# install.packages("MASS")
library(MASS)
# https://little-book-of-r-for-multivariate-analysis.readthedocs.io/en/latest/src/multivariateanalysis.html
wine<-read.table("wine.csv", sep=",")
View(wine)
names(wine)
wine.lda <- lda(wine$V1 ~ wine$V2 + wine$V3 + wine$V4 + wine$V5 + wine$V6 + wine$V7 + wine$V8 + wine$V9 + wine$V10 + wine$V11 + wine$V12 + wine$V13 + wine$V14)
#or
wine2.lda<-lda(win2$V1~ ., data=wine)
wine.lda
#coefficients of the LDA
wine.lda$scaling[,2]
wine.lda$scaling[,1]
wine.lda$scaling[,1:2]
#
wine.lda.values <- predict(wine.lda, wine[2:14])
#coefficients of the LDA
wine.lda$scaling[,2]
wine.lda$scaling[,1]
wine.lda$scaling[,1:2]
#we pass the test data in wine[2:14] in this case is all the database without the target
wine.lda.values <- predict(wine.lda, wine[2:14])
wine[,15]<- wine.lda.values$x[,2]
wine.lda.values$x[,2]
wine[,16]<- wine.lda.values$x[,1]
wine.lda.values$x[,1]
names(wine)[15]<-"LDA2"
names(wine)[16]<-"LDA1"
wine.lda.values
calcWithinGroupsVariance <- function(variable,groupvariable)
{
# find out how many values the group variable can take
groupvariable2 <- as.factor(groupvariable[[1]])
levels <- levels(groupvariable2)
numlevels <- length(levels)
# get the mean and standard deviation for each group:
numtotal <- 0
denomtotal <- 0
for (i in 1:numlevels)
{
leveli <- levels[i]
levelidata <- variable[groupvariable==leveli,]
levelilength <- length(levelidata)
# get the standard deviation for group i:
sdi <- sd(levelidata)
numi <- (levelilength - 1)*(sdi * sdi)
denomi <- levelilength
numtotal <- numtotal + numi
denomtotal <- denomtotal + denomi
}
# calculate the within-groups variance
Vw <- numtotal / (denomtotal - numlevels)
return(Vw)
}
groupStandardise <- function(variables, groupvariable)
{
# find out how many variables we have
variables <- as.data.frame(variables)
numvariables <- length(variables)
# find the variable names
variablenames <- colnames(variables)
# calculate the group-standardised version of each variable
for (i in 1:numvariables)
{
variablei <- variables[i]
variablei_name <- variablenames[i]
variablei_Vw <- calcWithinGroupsVariance(variablei, groupvariable)
variablei_mean <- mean(as.matrix(variablei))
variablei_new <- (variablei - variablei_mean)/(sqrt(variablei_Vw))
data_length <- nrow(variablei)
if (i == 1) { variables_new <- data.frame(row.names=seq(1,data_length)) }
variables_new[`variablei_name`] <- variablei_new
}
return(variables_new)
}
calcBetweenGroupsVariance <- function(variable,groupvariable)
{
# find out how many values the group variable can take
groupvariable2 <- as.factor(groupvariable[[1]])
levels <- levels(groupvariable2)
numlevels <- length(levels)
# calculate the overall grand mean:
grandmean <- mean(as.matrix(variable) )
# get the mean and standard deviation for each group:
numtotal <- 0
denomtotal <- 0
for (i in 1:numlevels)
{
leveli <- levels[i]
levelidata <- variable[groupvariable==leveli,]
levelilength <- length(levelidata)
# get the mean and standard deviation for group i:
meani <- mean( as.matrix(levelidata) )
sdi <- sd(levelidata)
numi <- levelilength * ((meani - grandmean)^2)
denomi <- levelilength
numtotal <- numtotal + numi
denomtotal <- denomtotal + denomi
}
# calculate the between-groups variance
Vb <- numtotal / (numlevels - 1)
Vb <- Vb[[1]]
return(Vb)
}
calcSeparations <- function(variables,groupvariable)
{
# find out how many variables we have
variables <- as.data.frame(variables)
numvariables <- length(variables)
# find the variable names
variablenames <- colnames(variables)
# calculate the separation for each variable
for (i in 1:numvariables)
{
variablei <- variables[i]
variablename <- variablenames[i]
Vw <- calcWithinGroupsVariance(variablei, groupvariable)
Vb <- calcBetweenGroupsVariance(variablei, groupvariable)
sep <- Vb/Vw
print(paste("variable",variablename,"Vw=",Vw,"Vb=",Vb,"separation=",sep))
}
}
groupstandardisedconcentrations <- groupStandardise(wine[2:14], wine[1])
calcSeparations(wine.lda.values$x,wine[1])
help("predict.lda")
